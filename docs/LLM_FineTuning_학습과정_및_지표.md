# LLM Fine-Tuning 학습 과정 및 지표

> Epoch, Loss, 자동 측정 지표, 최적 모델 선택 등 학습 과정에서 알아야 할 내용을 정리합니다.

---

## 1. Epoch

### 1-1. Epoch란?

```
전체 학습 데이터 2,500개를 처음부터 끝까지 1번 학습 = 1 epoch

3 epoch = 같은 2,500개 데이터를 3번 반복해서 학습합니다
```

```
비유로 설명하면:

  시험 공부할 때 교과서를 몇 회독 하는 것과 같습니다.

  1회독: 전체 내용을 한 번 훑음 → 대략적으로 이해
  2회독: 놓쳤던 부분을 잡아냄 → 이해도 상승
  3회독: 세부 내용까지 숙지 → 거의 다 익힘
  5회독: 거의 외우는 수준 → 응용력은 오히려 떨어질 수 있음
  10회독: 달달 외워버림 → 시험에 안 나온 문제는 못 풀게 됨 (과적합)
```

### 1-2. Epoch 수에 따른 성능 곡선

```
성능 (정확도)
  ↑
  │                            과적합 시작
  │                              ↓
  │                         ┌────●────── 학습 데이터 성능 (계속 오름)
  │                    ╭────╯   ╱
  │               ╭────╯       ╱
  │          ╭────╯    ●──────●───── 검증 데이터 성능 (꺾이기 시작)
  │     ╭────╯        ╱        ╲
  │╭────╯            ╱          ╲
  ││               ╱             ╲
  │╯             ╱
  │            ╱
  │          ╱
  │        ╱     ★ 이 지점이 최적 epoch (보통 2~4 사이)
  │      ╱
  │    ╱
  │  ╱
  │╱
  └──────────────────────────────────────────→ Epoch
    0    1    2    3    4    5    6    7    8

  ── 학습 데이터 성능: epoch가 늘수록 계속 올라갑니다
  ── 검증 데이터 성능: 올라가다가 어느 순간 꺾입니다
                     ↑
              이 꺾이는 지점이 "과적합"의 시작입니다
```

### 1-3. 과적합(Overfitting)

```
비유:
  수학 문제집을 10번 풀었더니 답을 외워버렸습니다.
  → 같은 문제집에서 출제하면 100점
  → 새로운 문제가 나오면 못 풀게 됨

구체적인 예시:

  학습 데이터에 이런 게 있었다고 합시다:
  User: "절점 1번에 X방향 10kN 하중을 추가해줘"
  Assistant: {"name":"add_nodal_load","args":{"node_id":1,...}}

  [적절한 학습 (3 epoch)]
  새로운 질문: "절점 5번에 Y방향 20kN 하중을 넣어줘"
  → {"name":"add_nodal_load","args":{"node_id":5,"direction":"Y","value":20}}
  → ✅ 패턴을 이해해서 응용합니다

  [과적합 (10 epoch)]
  새로운 질문: "절점 5번에 Y방향 20kN 하중을 넣어줘"
  → {"name":"add_nodal_load","args":{"node_id":1,"direction":"X","value":10}}
  → ❌ 학습 데이터의 답을 외워서 그대로 뱉습니다
```

### 1-4. Epoch별 수치 예상

```
Qwen2.5-1.5B + QLoRA + 건축구조 데이터 2,500개 기준:

┌────────┬──────────┬──────────┬──────────┬──────────┬──────────────┐
│ Epoch  │ Train    │ Val      │ Tool     │ JSON     │ 상태          │
│        │ Loss     │ Loss     │ Name Acc │ Valid    │              │
├────────┼──────────┼──────────┼──────────┼──────────┼──────────────┤
│ 0.5    │ 2.1      │ 2.0      │ ~55%     │ ~70%     │ 학습 초기     │
│ 1      │ 1.4      │ 1.35     │ ~75%     │ ~85%     │ 급격한 향상   │
│ 2      │ 0.8      │ 0.82     │ ~90%     │ ~96%     │ 거의 수렴     │
│ 3      │ 0.5      │ 0.55     │ ~95%     │ ~99%     │ ★ 최적 구간  │
│ 4      │ 0.35     │ 0.58     │ ~95%     │ ~99%     │ 미세 개선     │
│ 5      │ 0.25     │ 0.65     │ ~94%     │ ~98%     │ ⚠️ 과적합    │
│ 7      │ 0.15     │ 0.80     │ ~91%     │ ~96%     │ ❌ 성능 하락  │
│ 10     │ 0.08     │ 1.10     │ ~85%     │ ~90%     │ ❌ 심각한 하락│
└────────┼──────────┼──────────┼──────────┼──────────┼──────────────┘
         │          │
         │          └─ 검증 Loss가 올라가기 시작하면 과적합 신호입니다
         └─ 학습 Loss는 계속 내려갑니다 (외우고 있는 것)
```

### 1-5. Loss 곡선

```
Loss
(낮을수록 좋음)
  ↑
 2.0│╲
    │ ╲╲
 1.5│  ╲ ╲
    │   ╲  ╲
 1.0│    ╲   ╲──────── Val Loss (꺾이며 올라감)
    │     ╲  ╱
 0.8│      ╳    ← 이 교차점 직전이 최적입니다
    │     ╱ ╲
 0.5│    ╱   ╲
    │   ╱     ╲
 0.3│  ╱       ╲──── Train Loss (계속 내려감)
    │ ╱
 0.1│╱
    └──────────────────────────────────→ Epoch
     0    1    2    3    4    5    6    7

  최적 구간: epoch 2~4 (두 곡선이 가장 가까운 구간)
```

### 1-6. 최적 Epoch에 영향을 주는 요소

```
┌──────────────────────┬────────────────┬──────────────────┐
│ 요소                  │ 적은 epoch 필요 │ 많은 epoch 필요   │
├──────────────────────┼────────────────┼──────────────────┤
│ 데이터 양이 많으면     │ ✅ 1~2 epoch   │                  │
│ 데이터 양이 적으면     │                │ ✅ 3~5 epoch     │
├──────────────────────┼────────────────┼──────────────────┤
│ 데이터 품질이 높으면   │ ✅ 빨리 수렴    │                  │
│ 데이터 품질이 낮으면   │                │ ✅ 더 반복 필요    │
├──────────────────────┼────────────────┼──────────────────┤
│ 태스크가 단순하면      │ ✅ 빨리 학습    │                  │
│ (단일 tool calling)   │                │                  │
│ 태스크가 복잡하면      │                │ ✅ 더 반복 필요    │
│ (다단계 추론)          │                │                  │
├──────────────────────┼────────────────┼──────────────────┤
│ LoRA rank가 크면      │ ✅ 표현력 충분   │                  │
│ (r=16, 32)           │                │                  │
│ LoRA rank가 작으면    │                │ ✅ 더 반복 필요    │
│ (r=4, 8)             │                │                  │
└──────────────────────┴────────────────┴──────────────────┘

이 프로젝트 기준 (데이터 2,500개 + r=8 + 도메인 tool calling):
→ 3 epoch가 적절한 출발점입니다
→ 실험해보고 2~4 사이에서 최적값을 찾으면 됩니다
```

### 1-7. Early Stopping

검증 Loss가 연속 N번 올라가면 학습을 자동으로 중단하는 기법입니다.

```
  epoch 1: val_loss = 1.35  → 내려감 ✅ 계속
  epoch 2: val_loss = 0.82  → 내려감 ✅ 계속
  epoch 3: val_loss = 0.55  → 내려감 ✅ 계속 (★ 최저점 저장)
  epoch 4: val_loss = 0.58  → 올라감 ⚠️ 1회
  epoch 5: val_loss = 0.65  → 올라감 ⚠️ 2회
  epoch 6: val_loss = 0.72  → 올라감 ⚠️ 3회 → 자동 중단!

  최종 모델 = epoch 3에서 저장해둔 체크포인트를 사용합니다
```

코드 설정:

```python
training_args = TrainingArguments(
    num_train_epochs=10,                    # 넉넉하게 설정해두고
    eval_strategy="epoch",                  # 매 epoch마다 검증하고
    save_strategy="epoch",                  # 매 epoch마다 저장하고
    load_best_model_at_end=True,            # 최적 모델을 자동 선택합니다
    metric_for_best_model="eval_loss",      # 검증 Loss 기준으로 판단합니다
)

→ 10 epoch까지 돌 수 있게 해두지만,
  실제로는 3~4 epoch에서 알아서 최적 모델을 골라줍니다
```

---

## 2. Loss (손실 함수)

### 2-1. Loss가 뭔가요?

```
비유로 설명하면:

  시험을 보고 채점하는 것과 같습니다.

  모델이 답을 생성합니다 (예측)
  정답과 비교합니다 (실제 데이터)
  얼마나 틀렸는지 점수를 매깁니다 (= Loss)

  Loss가 높다 = 많이 틀렸다
  Loss가 낮다 = 잘 맞혔다
```

### 2-2. 어떻게 계산되나요? (Cross-Entropy Loss)

LLM의 학습에서는 "다음 토큰을 얼마나 잘 예측했는가"를 측정합니다.

```
학습 데이터의 정답:
  User: "서울 날씨 알려줘"
  Assistant: {"name":"get_weather","arguments":{"city":"Seoul"}}

모델이 한 토큰씩 예측합니다:

  [잘 맞힌 경우]
  입력: {"name":"get_          ← 여기까지 주어졌을 때
  정답: weather                ← 다음에 나와야 할 토큰
  모델 예측 확률:
    "weather"  → 85%  ✅ 높을수록 좋습니다
    "info"     → 8%
    "data"     → 4%

  Loss = -log(0.85) = 0.16    ← 잘 맞혔으므로 Loss가 낮습니다


  [못 맞힌 경우]
  입력: {"name":"get_
  정답: weather
  모델 예측 확률:
    "weather"  → 5%   ❌ 정답인데 확률이 낮습니다
    "info"     → 30%
    "data"     → 25%

  Loss = -log(0.05) = 3.0     ← 못 맞혔으므로 Loss가 높습니다
```

```
이걸 전체 토큰에 대해 평균 냅니다:

  토큰1 loss: 0.16
  토큰2 loss: 0.22
  토큰3 loss: 0.45
  토큰4 loss: 0.18
  ...
  전체 평균 = 0.35   ← 이게 그 스텝의 Loss입니다
```

### 2-3. Train Loss vs Validation Loss

```
Train Loss (학습 Loss):
  → 학습 데이터에 대한 Loss
  → "공부하고 있는 교과서 문제를 얼마나 잘 푸는가"
  → 학습이 진행되면 계속 내려갑니다 (당연히 — 계속 보는 문제니까)

Validation Loss (검증 Loss):
  → 학습에 사용하지 않은 별도 데이터에 대한 Loss
  → "처음 보는 시험 문제를 얼마나 잘 푸는가"
  → 진짜 실력을 보여주는 지표입니다
```

```
두 Loss의 관계:

  정상적인 학습:
    Train Loss:  2.0 → 1.0 → 0.5 → 0.3     (계속 내려감)
    Val Loss:    2.0 → 1.1 → 0.6 → 0.55     (같이 내려감) ✅ 좋습니다

  과적합 (Overfitting):
    Train Loss:  2.0 → 1.0 → 0.5 → 0.1     (계속 내려감)
    Val Loss:    2.0 → 1.1 → 0.6 → 0.8     (올라가기 시작) ❌ 외우고 있습니다

  Val Loss가 올라가기 시작하는 지점 = 학습을 멈춰야 하는 지점
```

### 2-4. Validation은 어떻게 측정하나요?

데이터를 나눌 때 일부를 검증용으로 떼어놓으면 자동으로 측정됩니다.

```
전체 데이터 2,500개

┌─────────────────────────────────────────────┐
│ Train (학습용): 2,000개 (80%)                │ ← 이걸로 학습합니다
├─────────────────────────────────────────────┤
│ Validation (검증용): 250개 (10%)             │ ← 이걸로 Loss를 측정합니다
├─────────────────────────────────────────────┤
│ Test (최종 평가용): 250개 (10%)              │ ← 학습 끝난 후 최종 평가용
└─────────────────────────────────────────────┘

검증 데이터는 학습에 절대 사용되지 않습니다.
그래서 "처음 보는 문제"에 대한 실력을 측정할 수 있습니다.
```

---

## 3. 학습 과정에서 자동으로 일어나는 일

`trainer.train()`을 실행하면 매 스텝마다 이 과정이 반복됩니다.

```
┌─────────────────────────────────────────────────────────────┐
│  Step 1: 데이터 배치를 가져옵니다                              │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ 학습 데이터 1개:                                     │    │
│  │ User: "서울 날씨 알려줘"                              │    │
│  │ Assistant: {"name":"get_weather","args":{...}}       │    │
│  └─────────────────────────────────────────────────────┘    │
│                        │                                    │
│                        ▼                                    │
│  Step 2: 모델이 예측합니다 (Forward Pass)                     │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ 각 토큰 위치에서 "다음 토큰이 뭘까?" 확률을 계산합니다  │    │
│  │ → GPU에서 28개 레이어를 통과하며 행렬 곱셈 수행        │    │
│  └─────────────────────────────────────────────────────┘    │
│                        │                                    │
│                        ▼                                    │
│  Step 3: Loss를 계산합니다 ← ★ 자동으로 계산됩니다           │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ 모델 예측 vs 정답을 비교                              │    │
│  │ Cross-Entropy Loss = 1.45 (예시)                    │    │
│  │                                                     │    │
│  │ 콘솔에 출력됩니다:                                    │    │
│  │ {'loss': 1.45, 'learning_rate': 0.0002, 'epoch': 0.1}│   │
│  └─────────────────────────────────────────────────────┘    │
│                        │                                    │
│                        ▼                                    │
│  Step 4: 가중치를 업데이트합니다 (Backward Pass)               │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ "Loss를 줄이려면 가중치를 어느 방향으로 바꿔야 하지?"   │    │
│  │ → 그래디언트 계산 (미분)                              │    │
│  │ → 옵티마이저가 가중치를 조금씩 수정                    │    │
│  └─────────────────────────────────────────────────────┘    │
│                        │                                    │
│                        ▼                                    │
│  Step 5: 다음 배치로 넘어갑니다 → Step 1부터 반복             │
│                                                             │
└─────────────────────────────────────────────────────────────┘

이 전체 과정이 trainer.train() 한 줄 안에 들어있습니다.
Loss 계산, 그래디언트 계산, 가중치 업데이트 모두 자동입니다.
```

실제 콘솔 출력 예시:

```
Step 10:   {'loss': 2.15, 'lr': 0.00018, 'epoch': 0.03}
Step 20:   {'loss': 1.82, 'lr': 0.00019, 'epoch': 0.06}
Step 30:   {'loss': 1.45, 'lr': 0.00020, 'epoch': 0.10}
...
Step 300:  {'loss': 0.38, 'lr': 0.00010, 'epoch': 1.00}  ← 1 epoch 완료
Step 600:  {'loss': 0.25, 'lr': 0.00005, 'epoch': 2.00}  ← 2 epoch 완료
Step 900:  {'loss': 0.18, 'lr': 0.00001, 'epoch': 3.00}  ← 3 epoch 완료

loss가 내려가는 게 보이면 → 모델이 점점 잘 학습하고 있다는 뜻입니다.
logging_steps=10 으로 설정하면 10스텝마다 출력됩니다.
```

---

## 4. PyTorch + HuggingFace 기본 제공 지표 전체 목록

### 4-1. 매 스텝마다 자동 출력되는 지표

```
┌──────────────────┬──────────────────────────────────────────────────────┐
│ 지표              │ 설명                                                │
├──────────────────┼──────────────────────────────────────────────────────┤
│ loss             │ 학습 데이터에 대한 Cross-Entropy Loss입니다.          │
│ (Train Loss)     │ "다음 토큰을 얼마나 잘 예측했는가"를 측정합니다.       │
│                  │                                                      │
│                  │ 높다(2.0+) = 거의 못 맞히고 있습니다                   │
│                  │ 중간(0.5~1.0) = 학습이 진행 중입니다                  │
│                  │ 낮다(0.3 이하) = 잘 학습되고 있습니다                  │
│                  │                                                      │
│                  │ ★ 가장 핵심적인 지표입니다.                           │
│                  │ 이 값이 내려가야 학습이 되고 있는 것입니다.             │
├──────────────────┼──────────────────────────────────────────────────────┤
│ grad_norm        │ 그래디언트의 크기(L2 노름)입니다.                     │
│ (Gradient Norm)  │ "이번 데이터 기준으로 가중치를 얼마나 수정해야 하는가"  │
│                  │ 를 보여줍니다.                                        │
│                  │                                                      │
│                  │ 정상 범위: 0.1 ~ 2.0 정도                            │
│                  │ 너무 크면(10+) = 학습이 불안정합니다 (발산 위험)       │
│                  │ 너무 작으면(0.001 이하) = 학습이 거의 멈춘 것입니다    │
│                  │                                                      │
│                  │ max_grad_norm=1.0 (기본값)으로 상한선을 제어합니다.    │
├──────────────────┼──────────────────────────────────────────────────────┤
│ learning_rate    │ 현재 학습률입니다.                                    │
│ (Learning Rate)  │ "한 번 수정할 때 얼마나 과감하게 바꿀 것인가"의        │
│                  │ 감도 설정값입니다.                                    │
│                  │                                                      │
│                  │ 학습 중에 스케줄에 따라 자동으로 변합니다:              │
│                  │   warmup: 0에서 서서히 올라감 (0 → 2e-4)             │
│                  │   이후: 서서히 내려감 (2e-4 → 0)                     │
├──────────────────┼──────────────────────────────────────────────────────┤
│ epoch            │ 전체 데이터를 몇 번 반복했는지를 나타냅니다.           │
│                  │                                                      │
│                  │ 0.5 = 전체 데이터의 절반을 학습함                     │
│                  │ 1.0 = 전체 데이터를 1번 완주함                        │
│                  │ 3.0 = 전체 데이터를 3번 반복함                        │
└──────────────────┴──────────────────────────────────────────────────────┘
```

### 4-2. 검증(Evaluation) 시 자동 출력되는 지표

`eval_strategy="epoch"` 설정 시 검증 시점마다 출력됩니다.

```
┌───────────────────────────┬────────────────────────────────────────────────┐
│ 지표                       │ 설명                                          │
├───────────────────────────┼────────────────────────────────────────────────┤
│ eval_loss                 │ 검증 데이터에 대한 Cross-Entropy Loss입니다.    │
│ (Validation Loss)         │ train loss와 같은 계산이지만,                  │
│                           │ 학습에 사용하지 않은 데이터로 측정합니다.        │
│                           │                                                │
│                           │ ★ 과적합을 판단하는 핵심 지표입니다.            │
│                           │   이 값이 올라가기 시작하면 = 과적합 시작       │
│                           │   이 값이 가장 낮았던 시점 = 최적 모델          │
│                           │                                                │
│                           │ load_best_model_at_end=True 설정 시            │
│                           │ 이 값이 가장 낮은 checkpoint를 자동 선택합니다.  │
├───────────────────────────┼────────────────────────────────────────────────┤
│ eval_runtime              │ 검증에 걸린 총 시간(초)입니다.                  │
│                           │                                                │
│                           │ 예: 12.5 = 검증 데이터 전체를 평가하는 데       │
│                           │     12.5초 걸렸습니다.                         │
│                           │                                                │
│                           │ 이 값이 갑자기 크게 늘면 메모리 문제나          │
│                           │ GPU 병목이 생겼을 수 있습니다.                  │
├───────────────────────────┼────────────────────────────────────────────────┤
│ eval_samples_per_second   │ 초당 처리한 검증 샘플 수입니다.                 │
│                           │                                                │
│                           │ 예: 20.0 = 1초에 20개 데이터를 평가했습니다.    │
│                           │ GPU 성능과 배치 크기에 따라 달라집니다.          │
│                           │ 추론 속도를 가늠하는 데 참고할 수 있습니다.      │
├───────────────────────────┼────────────────────────────────────────────────┤
│ eval_steps_per_second     │ 초당 처리한 검증 스텝 수입니다.                 │
│                           │                                                │
│                           │ 1 step = 1 batch 처리                         │
│                           │ eval_samples_per_second와 같은 맥락이지만      │
│                           │ 배치 단위로 표현한 것입니다.                    │
└───────────────────────────┴────────────────────────────────────────────────┘
```

### 4-3. 학습 완료 후 자동 출력되는 지표

`trainer.train()`이 끝나면 최종 요약이 출력됩니다.

```
┌───────────────────────────┬────────────────────────────────────────────────┐
│ 지표                       │ 설명                                          │
├───────────────────────────┼────────────────────────────────────────────────┤
│ global_step               │ 총 학습 스텝 수입니다.                         │
│                           │                                                │
│                           │ 예: 900 = 가중치를 900번 업데이트했습니다.       │
│                           │                                                │
│                           │ 계산: (데이터 수 / batch_size)                  │
│                           │       × epoch 수                              │
│                           │       / gradient_accumulation_steps            │
│                           │ = (2500 / 1) × 3 / 8 ≈ 937 스텝              │
├───────────────────────────┼────────────────────────────────────────────────┤
│ training_loss             │ 전체 학습 과정의 평균 Loss입니다.               │
│ (= train_loss)            │                                                │
│                           │ 모든 스텝의 loss를 평균 낸 값입니다.            │
│                           │ 학습 초반의 높은 loss도 포함되어 있으므로        │
│                           │ 마지막 스텝의 loss보다 높습니다.                │
├───────────────────────────┼────────────────────────────────────────────────┤
│ train_runtime             │ 학습에 걸린 총 시간(초)입니다.                  │
│                           │                                                │
│                           │ 예: 5400.0 = 1시간 30분 걸렸습니다.            │
├───────────────────────────┼────────────────────────────────────────────────┤
│ train_samples_per_second  │ 초당 학습한 샘플 수입니다.                      │
│                           │                                                │
│                           │ 예: 1.39 = 1초에 1.39개 데이터를 학습했습니다.  │
│                           │ 학습 효율성을 보여줍니다.                       │
│                           │ Unsloth 적용 전/후 비교할 때 유용합니다.        │
├───────────────────────────┼────────────────────────────────────────────────┤
│ train_steps_per_second    │ 초당 학습한 스텝 수입니다.                      │
│                           │                                                │
│                           │ 예: 0.17 = 1스텝에 약 5.9초 걸렸습니다.        │
│                           │ (gradient_accumulation=8이면                   │
│                           │  실제로 8개 미니배치를 모아서 1스텝 처리)        │
├───────────────────────────┼────────────────────────────────────────────────┤
│ total_flos                │ 총 부동소수점 연산 횟수 (FLOPs)입니다.          │
│ (Floating Point           │                                                │
│  Operations)              │ 예: 1.23e+15 = 1,230조 번의 연산               │
│                           │ 모델 크기 × 데이터 수 × epoch에 비례합니다.     │
│                           │ 학습 비용을 정량적으로 비교할 때 씁니다.         │
├───────────────────────────┼────────────────────────────────────────────────┤
│ epoch                     │ 완료된 epoch 수입니다.                          │
│                           │ 3.0 = 전체 데이터를 3번 반복 완료했습니다.      │
└───────────────────────────┴────────────────────────────────────────────────┘
```

### 4-4. wandb / TensorBoard 연동 시 추가 지표

`report_to="wandb"` 또는 `report_to="tensorboard"` 설정 시 위의 모든 지표가 그래프로 시각화되고, 시스템 지표도 추가 기록됩니다.

```
┌───────────────────────────┬────────────────────────────────────────────────┐
│ 지표                       │ 설명                                          │
├───────────────────────────┼────────────────────────────────────────────────┤
│ train/loss                │ 학습 Loss 그래프입니다.                        │
├───────────────────────────┼────────────────────────────────────────────────┤
│ train/grad_norm           │ 그래디언트 노름 그래프입니다.                   │
├───────────────────────────┼────────────────────────────────────────────────┤
│ train/learning_rate       │ 학습률 변화 곡선입니다.                        │
│                           │ warmup → peak → decay 패턴이 보여야 정상입니다.│
├───────────────────────────┼────────────────────────────────────────────────┤
│ eval/loss                 │ 검증 Loss 변화 곡선입니다.                     │
│                           │ train/loss와 나란히 비교하면                   │
│                           │ 과적합 여부를 시각적으로 판단할 수 있습니다.     │
├───────────────────────────┼────────────────────────────────────────────────┤
│ system/gpu_memory_allocated│ GPU 메모리(VRAM) 사용량입니다. (wandb 전용)    │
│                           │ 6GB 한계에 가까워지면 OOM 위험이 있습니다.      │
├───────────────────────────┼────────────────────────────────────────────────┤
│ system/gpu_utilization    │ GPU 사용률(%)입니다. (wandb 전용)               │
│                           │ 90%+ → GPU를 잘 활용하고 있습니다              │
│                           │ 50% 이하 → 데이터 로딩이 병목일 수 있습니다     │
├───────────────────────────┼────────────────────────────────────────────────┤
│ system/cpu_utilization    │ CPU 사용률(%)입니다. (wandb 전용)               │
│                           │ CPU가 너무 낮으면 데이터 파이프라인 문제입니다.  │
└───────────────────────────┴────────────────────────────────────────────────┘
```

---

## 5. 자동 지표 vs 직접 구현 지표

### 5-1. 구분

```
자동으로 측정되는 것:
  ✅ Train Loss       → 매 스텝마다 자동
  ✅ Validation Loss  → eval_strategy 설정 시 자동
  ✅ Learning Rate    → 매 스텝마다 자동
  ✅ Grad Norm        → 매 스텝마다 자동
  ✅ Epoch 진행률     → 매 스텝마다 자동
  ✅ Runtime/속도     → 자동 집계

직접 구현해야 하는 것:
  ❌ Tool Name Accuracy   → 모델 출력에서 tool name을 추출해서 정답과 비교
  ❌ Parameter Accuracy   → 모델 출력에서 파라미터를 추출해서 정답과 비교
  ❌ JSON Validity        → 모델 출력이 json.loads()로 파싱 가능한지 확인
  ❌ Hallucination Rate   → 모델이 없는 파라미터를 생성했는지 확인
```

### 5-2. 커스텀 지표는 언제 측정하나요?

```
보통 학습 끝난 후에 별도 스크립트로 평가합니다:

  1. 학습 완료 (Loss 기반으로 최적 모델 자동 선택)
  2. 테스트 데이터 250개를 모델에 입력
  3. 출력 결과를 파싱해서 정답과 비교
  4. Tool Name Acc, Param Acc, JSON Valid 등을 계산

  이 평가 스크립트는 직접 Python으로 작성해야 합니다.
  하지만 로직 자체는 단순합니다 (문자열 비교, JSON 파싱).
```

---

## 6. 전체 지표 한눈에 보기

```
┌──────────┬──────────────────────────┬─────────┬────────────────────────┐
│ 카테고리  │ 지표                      │ 중요도   │ 봐야 할 이유           │
├──────────┼──────────────────────────┼─────────┼────────────────────────┤
│          │ loss (Train Loss)        │ ★★★★★ │ 학습이 되고 있는지 확인  │
│  매 스텝  │ grad_norm               │ ★★★    │ 학습 안정성 확인        │
│  자동출력 │ learning_rate            │ ★★     │ 스케줄이 정상인지 확인   │
│          │ epoch                    │ ★★     │ 진행 상황 확인          │
├──────────┼──────────────────────────┼─────────┼────────────────────────┤
│          │ eval_loss                │ ★★★★★ │ 과적합 판단, 최적 모델  │
│  검증 시  │ eval_runtime             │ ★      │ 검증 속도 확인          │
│  자동출력 │ eval_samples_per_second  │ ★      │ 추론 속도 참고          │
│          │ eval_steps_per_second    │ ★      │ 추론 속도 참고          │
├──────────┼──────────────────────────┼─────────┼────────────────────────┤
│          │ training_loss            │ ★★★    │ 전체 학습 품질 요약     │
│  학습     │ global_step             │ ★★     │ 총 학습량 확인          │
│  완료 후  │ train_runtime            │ ★★     │ 소요 시간 기록          │
│          │ train_samples_per_second │ ★★     │ 학습 효율성 비교        │
│          │ train_steps_per_second   │ ★★     │ 학습 효율성 비교        │
│          │ total_flos               │ ★      │ 연산량 정량 비교        │
├──────────┼──────────────────────────┼─────────┼────────────────────────┤
│  wandb/  │ gpu_memory_allocated     │ ★★★★  │ OOM 방지, VRAM 관리    │
│  TB 연동 │ gpu_utilization          │ ★★★    │ GPU 활용도 확인        │
│  시 추가 │ cpu_utilization          │ ★★     │ 데이터 병목 확인        │
└──────────┴──────────────────────────┴─────────┴────────────────────────┘

실전에서 주로 보는 것은 3개입니다:
  1. loss (Train Loss)    → "계속 내려가고 있는가?"
  2. eval_loss            → "올라가기 시작했는가?" (과적합 판단)
  3. grad_norm            → "갑자기 튀는 값이 있는가?" (학습 안정성)
```

---

## 7. Grad Norm vs Learning Rate 차이

비슷해 보이지만 역할이 완전히 다릅니다.

### 7-1. 한 줄 차이

```
Learning Rate = 사람이 미리 정해놓은 "수정 강도 설정값"
Grad Norm     = 모델이 데이터를 보고 자동 계산한 "수정이 필요한 정도"
```

### 7-2. 비유

```
자동차 핸들로 비유:

  grad_norm      = "지금 도로가 얼마나 휘어있는가" (도로 상태)
                   → 커브가 심하면 크고, 직선이면 작습니다
                   → 데이터를 보고 자동으로 결정됩니다

  learning_rate  = "핸들을 얼마나 민감하게 반응하게 할 것인가" (핸들 감도 설정)
                   → 감도가 높으면 조금만 꺾어도 크게 움직입니다
                   → 사람이 미리 설정하는 값입니다
```

### 7-3. 실제 수정량

```
실제 가중치 수정량 = grad_norm × learning_rate

  grad_norm = 큰 커브  ×  learning_rate = 높은 감도  →  크게 수정
  grad_norm = 직선     ×  learning_rate = 높은 감도  →  적당히 수정
  grad_norm = 큰 커브  ×  learning_rate = 낮은 감도  →  적당히 수정
  grad_norm = 직선     ×  learning_rate = 낮은 감도  →  거의 안 수정
```

### 7-4. 수식

```
가중치 업데이트 공식 (단순화):

  새 가중치 = 기존 가중치 - learning_rate × gradient
                           ↑                ↑
                        사람이 설정         모델이 계산
                        (고정된 설정값)      (데이터마다 달라짐)

  grad_norm = 이 gradient의 전체 크기를 하나의 숫자로 요약한 것

구체적인 예시:
  gradient = [-0.3, 0.5, -0.1, 0.8, ...]   ← 각 가중치별 수정 방향과 크기
  grad_norm = √(0.3² + 0.5² + 0.1² + 0.8² + ...) = 1.2  ← 전체 크기 요약

  learning_rate = 0.0002  ← 사람이 설정한 감도

  실제 수정량 = 0.0002 × [-0.3, 0.5, -0.1, 0.8, ...]
             = [-0.00006, 0.0001, -0.00002, 0.00016, ...]
```

### 7-5. 학습 과정에서 각각 어떻게 변하는가

```
시간 →

Learning Rate (사람이 정한 스케줄대로 움직임):
        ╭────────╮
       ╱          ╲
      ╱            ╲
     ╱              ╲
────╱                ╲──────
  warmup    peak     decay
  → 예측 가능하고, 매끄러운 곡선입니다


Grad Norm (모델이 데이터를 보고 계산, 매번 다름):
  │╱╲   ╱╲
  ╱  ╲ ╱  ╲ ╱╲  ╱╲
 ╱    ╳    ╳  ╲╱  ╲   ╱╲╱╲╱╲
╱          ╲        ╲─╱
  → 들쭉날쭉하지만 전체적으로 줄어드는 경향입니다
  → 학습 초반: 많이 틀리니까 큽니다
  → 학습 후반: 거의 맞추니까 작아집니다
```

### 7-6. 핵심 차이 정리

```
┌──────────────────┬─────────────────────────┬─────────────────────────┐
│                  │ Learning Rate            │ Grad Norm               │
├──────────────────┼─────────────────────────┼─────────────────────────┤
│ 누가 결정하는가   │ 사람이 미리 설정합니다     │ 모델이 자동으로 계산합니다 │
├──────────────────┼─────────────────────────┼─────────────────────────┤
│ 언제 바뀌는가     │ 스케줄에 따라 서서히      │ 매 스텝마다 데이터에 따라 │
│                  │ 변합니다 (예측 가능)       │ 변합니다 (예측 불가)      │
├──────────────────┼─────────────────────────┼─────────────────────────┤
│ 무엇을 나타내는가 │ "얼마나 민감하게          │ "지금 이 데이터 기준으로  │
│                  │  반응할 것인가" (감도)     │  얼마나 틀렸는가" (오차)  │
├──────────────────┼─────────────────────────┼─────────────────────────┤
│ 비유             │ 핸들 감도 설정             │ 도로의 커브 정도         │
├──────────────────┼─────────────────────────┼─────────────────────────┤
│ 변화 패턴        │ warmup → peak → decay    │ 초반에 크고 후반에 작아짐 │
│                  │ (미리 정한 대로)           │ (학습이 잘 되고 있으면)   │
├──────────────────┼─────────────────────────┼─────────────────────────┤
│ 이상 신호        │ 스케줄대로 안 움직이면     │ 갑자기 튀면              │
│                  │ 설정 오류                 │ 학습 불안정 (데이터 문제)  │
└──────────────────┴─────────────────────────┴─────────────────────────┘
```

---

## 8. PyTorch 라이브러리 구조

PyTorch를 직접(raw) 쓸 수도 있지만, HuggingFace 고수준 라이브러리를 쓰는 것이 일반적입니다.

### 8-1. 라이브러리 관계도

```
┌─────────────────────────────────────────────────────────┐
│                  직접 쓰는 코드 (30~40줄)                 │
└─────────────────────┬───────────────────────────────────┘
                      │ 사용
                      ▼
┌─────────────────────────────────────────────────────────┐
│  trl (SFTTrainer)        ← 학습 실행을 간편하게          │
│  peft (LoRA, QLoRA)      ← 효율적 학습 방법              │
│  transformers (모델,토크나이저) ← 모델 로딩/관리           │
│  datasets (데이터 로딩)    ← 데이터셋 처리                │
│  bitsandbytes (양자화)    ← 4-bit 압축                   │
│  accelerate (GPU 관리)    ← 멀티GPU, 메모리 최적화        │
└─────────────────────┬───────────────────────────────────┘
                      │ 내부적으로 사용
                      ▼
┌─────────────────────────────────────────────────────────┐
│  PyTorch                                                │
│  → 텐서 연산, 자동 미분, GPU 연산 등 핵심 엔진            │
└─────────────────────┬───────────────────────────────────┘
                      │ 내부적으로 사용
                      ▼
┌─────────────────────────────────────────────────────────┐
│  CUDA                                                   │
│  → GPU 하드웨어와 통신                                    │
└─────────────────────────────────────────────────────────┘

직접 작성하는 코드는 맨 위 30~40줄뿐이고,
나머지는 라이브러리들이 알아서 처리해줍니다.
```

### 8-2. 실제 코드 (HuggingFace 방식, 약 30~40줄)

```python
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments
from peft import LoraConfig, get_peft_model
from trl import SFTTrainer
from datasets import load_dataset

# 1. 모델 로딩 (4-bit 양자화 포함)
model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-1.5B-Instruct",
    quantization_config=bnb_config,
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-1.5B-Instruct")

# 2. LoRA 설정
lora_config = LoraConfig(r=8, lora_alpha=16, target_modules="all-linear")
model = get_peft_model(model, lora_config)

# 3. 데이터셋 로딩
dataset = load_dataset("json", data_files="train_data.jsonl")

# 4. 학습 설정
training_args = TrainingArguments(
    output_dir="./checkpoints",
    per_device_train_batch_size=1,
    gradient_accumulation_steps=8,
    learning_rate=2e-4,
    num_train_epochs=3,
    fp16=True,
    eval_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
)

# 5. 학습 실행
trainer = SFTTrainer(
    model=model,
    args=training_args,
    train_dataset=dataset["train"],
    tokenizer=tokenizer,
)

trainer.train()    # ← 이 한 줄로 학습이 시작됩니다
trainer.save_model("./final-model")

# 실행:
# $ python train.py
```

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - First Fine-Tuning: Mini QLoRA Training\n",
    "\n",
    "This notebook performs a mini fine-tuning run with sample data to validate the full pipeline:\n",
    "- Load a quantized model and apply LoRA adapters\n",
    "- Train for 1-2 epochs on sample data\n",
    "- Monitor training loss\n",
    "- Compare model output before and after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "import torch\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "from datasets import Dataset\n",
    "from src.data_utils import load_jsonl, get_tokenizer, load_yaml_config\n",
    "from src.eval_metrics import parse_tool_calls_from_output, measure_vram_usage"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Apply LoRA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16, bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, quantization_config=bnb_config, device_map=\"auto\")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "lora_config = LoraConfig(r=8, lora_alpha=16, lora_dropout=0.05, target_modules=\"all-linear\", bias=\"none\", task_type=\"CAUSAL_LM\")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "tokenizer = get_tokenizer(MODEL_NAME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Fine-Tuning: Baseline Inference"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tools = json.load(open(\"../data/samples/gennx_tool_schemas_tier1.json\"))\n",
    "test_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a structural engineering assistant for GEN NX.\"},\n",
    "    {\"role\": \"user\", \"content\": \"\uC808\uC810 1\uBC88\uC744 \uC6D0\uC810\uC5D0 \uCD94\uAC00\uD574\uC918\"},\n",
    "]\n",
    "text = tokenizer.apply_chat_template(test_messages, tools=tools, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n",
    "baseline_response = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=False)\n",
    "print(\"=== Baseline Response ===\")\n",
    "print(baseline_response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "samples = load_jsonl(\"../data/samples/gennx_tool_calling_samples.jsonl\")\n",
    "train_dataset = Dataset.from_list(samples)\n",
    "print(f\"Training samples: {len(train_dataset)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (2 Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/checkpoints/notebook_test\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=2,\n",
    "    fp16=True, bf16=False,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    dataloader_pin_memory=False,\n",
    "    dataloader_num_workers=0,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    report_to=\"none\",\n",
    ")\n",
    "trainer = SFTTrainer(\n",
    "    model=model, tokenizer=tokenizer, args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    max_seq_length=2048, packing=False,\n",
    ")\n",
    "result = trainer.train()\n",
    "print(f\"Training loss: {result.training_loss:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "logs = [log for log in trainer.state.log_history if \"loss\" in log]\n",
    "steps = [log[\"step\"] for log in logs]\n",
    "losses = [log[\"loss\"] for log in logs]\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(steps, losses, marker=\"o\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Fine-Tuning: Inference Comparison"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(**inputs, max_new_tokens=512, do_sample=False)\n",
    "finetuned_response = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=False)\n",
    "print(\"=== Fine-Tuned Response ===\")\n",
    "print(finetuned_response)\n",
    "print(\"\\n=== Comparison ===\")\n",
    "print(f\"Baseline tool calls: {len(parse_tool_calls_from_output(baseline_response))}\")\n",
    "print(f\"Fine-tuned tool calls: {len(parse_tool_calls_from_output(finetuned_response))}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VRAM Usage"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "vram = measure_vram_usage()\n",
    "print(f\"VRAM: {vram['used_mb']:.0f} MB / {vram['total_mb']:.0f} MB ({vram['percent']:.1f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}